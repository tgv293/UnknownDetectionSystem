{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3808633,"sourceType":"datasetVersion","datasetId":2269875}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/MdAliAhnaf/frontal_3-category_face-mask_detection.git","metadata":{"_uuid":"0273fb7c-f600-4f2f-9fbf-7c172ac520fe","_cell_guid":"d4cf635a-b089-4427-b68c-65a83349afa3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T09:51:06.445754Z","iopub.execute_input":"2025-03-08T09:51:06.446087Z","iopub.status.idle":"2025-03-08T09:51:24.737253Z","shell.execute_reply.started":"2025-03-08T09:51:06.446034Z","shell.execute_reply":"2025-03-08T09:51:24.736137Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q condacolab\nimport condacolab\ncondacolab.install()","metadata":{"_uuid":"897d53f2-db66-47c3-a48d-618eeb15966f","_cell_guid":"033e999f-5786-448f-9b50-7ffdfcca9ed9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T09:51:24.739347Z","iopub.execute_input":"2025-03-08T09:51:24.739609Z","iopub.status.idle":"2025-03-08T09:51:41.042832Z","shell.execute_reply.started":"2025-03-08T09:51:24.739586Z","shell.execute_reply":"2025-03-08T09:51:41.041780Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0","metadata":{"_uuid":"ee1c0940-500b-4fd4-b492-cc68c7b30ac2","_cell_guid":"10f8a140-4dd0-4a6b-bb36-5988f92302b1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T09:54:12.086077Z","iopub.execute_input":"2025-03-08T09:54:12.086418Z","iopub.status.idle":"2025-03-08T09:56:07.413733Z","shell.execute_reply.started":"2025-03-08T09:54:12.086389Z","shell.execute_reply":"2025-03-08T09:56:07.412754Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n!pip install tensorflow==2.10.1 numpy==1.26.4 keras==2.10\n!pip install retina-face opencv-python pyyaml h5py\n!pip install tensorflow-io\n!pip install -U albumentations","metadata":{"_uuid":"1c3d3d32-04bb-498b-bc64-48120066ab84","_cell_guid":"d318cf74-d78b-4569-b60f-73636c602ca1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T09:56:41.656537Z","iopub.execute_input":"2025-03-08T09:56:41.656867Z","iopub.status.idle":"2025-03-08T09:57:45.484863Z","shell.execute_reply.started":"2025-03-08T09:56:41.656838Z","shell.execute_reply":"2025-03-08T09:57:45.483759Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport glob as gb\nimport scipy\nimport random\nimport seaborn as sns\nimport os\nfrom PIL import Image\nfrom tqdm import tqdm\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"a22aaef9-55a3-4d92-84bf-2719ba9b36ef","_cell_guid":"3bba9519-da56-4812-a078-74c2d438db7d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T10:13:33.131783Z","iopub.execute_input":"2025-03-08T10:13:33.132201Z","iopub.status.idle":"2025-03-08T10:13:33.139553Z","shell.execute_reply.started":"2025-03-08T10:13:33.132149Z","shell.execute_reply":"2025-03-08T10:13:33.138368Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure GPU Memory Growth\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\nfor device in physical_devices:\n    tf.config.experimental.set_memory_growth(device, True)\n\nprint(physical_devices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T10:13:38.434178Z","iopub.execute_input":"2025-03-08T10:13:38.434526Z","iopub.status.idle":"2025-03-08T10:13:38.439572Z","shell.execute_reply.started":"2025-03-08T10:13:38.434501Z","shell.execute_reply":"2025-03-08T10:13:38.438632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resize = 224   #input image size\nlearning_rate = 1e-4\nseed = 107\n#define the hyperparamets for traing te neural network\nINIT_LR = 1e-4\nEPOCHS = 50\nBS = 64\n#dir_mask = 'drive/MyDrive/content/mask_dataset/Dataset/with_mask'\n#dir_inc_mask = 'drive/MyDrive/content/mask_dataset/Dataset/mask_weared_incorrect'\n#dir_nomask = 'drive/MyDrive/content/mask_dataset/Dataset/without_mask'\n#TRAIN_DIR = 'drive/MyDrive/content/mask_dataset/Dataset'\n\ndir_mask = '/kaggle/working/frontal_3-category_face-mask_detection/mask_dataset/with_mask'\ndir_inc_mask = '/kaggle/working/frontal_3-category_face-mask_detection/mask_dataset/mask_weared_incorrect'\ndir_nomask = '/kaggle/working/frontal_3-category_face-mask_detection/mask_dataset/without_mask'\nTRAIN_DIR = '/kaggle/working/frontal_3-category_face-mask_detection/mask_dataset'\n\nassert os.path.exists(dir_mask), 'Could not find' + dir_mask\nassert os.path.exists(dir_inc_mask), 'Could not find' + dir_inc_mask\nassert os.path.exists(dir_nomask), 'Could not find' + dir_nomask","metadata":{"_uuid":"c02daa66-4cc7-4150-a439-e238ebabc9cc","_cell_guid":"a9ce5bcc-e052-40f1-933b-8002615b1d07","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T10:13:38.441012Z","iopub.execute_input":"2025-03-08T10:13:38.441345Z","iopub.status.idle":"2025-03-08T10:13:38.457910Z","shell.execute_reply.started":"2025-03-08T10:13:38.441298Z","shell.execute_reply":"2025-03-08T10:13:38.456987Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categories = []\nclass_count = []\ntrain_exm = 0\n\nfor f in tqdm(os.listdir(TRAIN_DIR)):\n    files = gb.glob(pathname=str(TRAIN_DIR  + '//' + f + '/*'))\n    categories.append(f)\n    class_count.append(len(files))\n    train_exm += len(files)\n\nsns.barplot(x=categories, y=class_count).set_title(\"distribution of train data\")\nplt.show()\nprint(train_exm)\n\n# Joining code starts here\n#CATEGORIES = [\"with_mask\", \"mask_weared_incorrect\", \"without_mask\"]\ndata = []\nlabels = []\n\nfor c in categories:\n    path = os.path.join(TRAIN_DIR, c)\n    for img in tqdm(os.listdir(path)):\n        img_path = os.path.join(path, img)\n        image = load_img(img_path, target_size=(resize, resize))\n        image = img_to_array(image)\n        image = preprocess_input(image)\n        \n        data.append(image)\n        labels.append(c)\n        \ndata= np.array(data, dtype=\"float32\")\nlabels = np.array(labels)","metadata":{"_uuid":"f77a809b-4b1b-43ac-954e-14fbf45c4e8a","_cell_guid":"6de919f8-5175-4e52-8078-58f93ba5d456","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T10:13:38.459485Z","iopub.execute_input":"2025-03-08T10:13:38.459754Z","iopub.status.idle":"2025-03-08T10:14:07.336865Z","shell.execute_reply.started":"2025-03-08T10:13:38.459734Z","shell.execute_reply":"2025-03-08T10:14:07.335979Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(labels)","metadata":{"_uuid":"024fa96c-9b60-4a1e-bb29-f12878207ff1","_cell_guid":"6037ca69-299a-4ed9-969c-027135a56d98","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T10:14:07.338040Z","iopub.execute_input":"2025-03-08T10:14:07.338316Z","iopub.status.idle":"2025-03-08T10:14:07.343674Z","shell.execute_reply.started":"2025-03-08T10:14:07.338290Z","shell.execute_reply":"2025-03-08T10:14:07.342635Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique, counts = np.unique(labels, return_counts=True)\ndict(zip(unique, counts))","metadata":{"_uuid":"7c36a55b-901b-493c-9f80-e6601634db43","_cell_guid":"7b1bbb70-cafd-4aa5-815f-8598b3f774a4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T10:14:07.344627Z","iopub.execute_input":"2025-03-08T10:14:07.344849Z","iopub.status.idle":"2025-03-08T10:14:07.364366Z","shell.execute_reply.started":"2025-03-08T10:14:07.344829Z","shell.execute_reply":"2025-03-08T10:14:07.363444Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Encode the labels in one hot encode form\nlb = LabelEncoder()\nlabels = lb.fit_transform(labels)\nlabels = to_categorical(labels)\nlabels","metadata":{"_uuid":"72b29e4f-095a-4663-b064-ac6544354931","_cell_guid":"bb5f2cf7-61c3-4e0c-ad91-553827eeb14e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T10:14:07.365154Z","iopub.execute_input":"2025-03-08T10:14:07.365377Z","iopub.status.idle":"2025-03-08T10:14:07.373476Z","shell.execute_reply.started":"2025-03-08T10:14:07.365357Z","shell.execute_reply":"2025-03-08T10:14:07.372802Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"AugmentedData = ImageDataGenerator(\n    zoom_range=0.15,  # Giới hạn phóng to/thu nhỏ từ 90% đến 110% của kích thước ảnh\n    rotation_range=20,  # Giới hạn góc quay chỉ từ -15° đến 15°\n    width_shift_range=0.2,  # Dịch chuyển chiều ngang tối đa 10%\n    height_shift_range=0.2,  # Dịch chuyển chiều dọc tối đa 10%\n    shear_range=0.15,  # Giới hạn độ biến dạng shear\n    horizontal_flip=True,  # Lật ảnh ngang\n    fill_mode=\"nearest\"  # Sử dụng giá trị gần nhất để điền vào các vùng trống sau khi biến đổi\n)","metadata":{"_uuid":"39c71b41-da00-471a-ae16-2800712a57a9","_cell_guid":"c1065858-783f-4a8c-9a65-2b1780c8e001","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T10:14:07.375177Z","iopub.execute_input":"2025-03-08T10:14:07.375410Z","iopub.status.idle":"2025-03-08T10:14:07.389346Z","shell.execute_reply.started":"2025-03-08T10:14:07.375389Z","shell.execute_reply":"2025-03-08T10:14:07.388600Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#define the model\nbaseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\nbaseModel.summary()\n\n# construct the head of the model that will be placed on top of the\n# the base model (A simple CNN as the Head model) \nheadModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(7, 7))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(256, activation=\"relu\")(headModel)\nheadModel = Dropout(0.25)(headModel)\nheadModel = Dense(3, activation=\"softmax\")(headModel)\n\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n\n# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the first training process\nfor layer in baseModel.layers:\n\tlayer.trainable = False","metadata":{"_uuid":"8460a349-bfa5-4ffc-85d9-3269e9fe3a11","_cell_guid":"150ca4a5-5a08-490f-ba3c-2ac108d0e5df","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T10:14:07.390337Z","iopub.execute_input":"2025-03-08T10:14:07.390591Z","iopub.status.idle":"2025-03-08T10:14:09.182781Z","shell.execute_reply.started":"2025-03-08T10:14:07.390559Z","shell.execute_reply":"2025-03-08T10:14:09.182007Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#divide data into training and testing sets\n(trainX, testX, trainY, testY) = train_test_split(data, labels,\n\ttest_size=0.2, stratify=labels, random_state=42)\nprint(f\"Shape of x_train: {trainX.shape}\")\nprint(f\"Shape of y_train: {trainY.shape}\")\nprint()\nprint(f\"Shape of x_test: {testX.shape}\")\nprint(f\"Shape of y_test: {testY.shape}\")","metadata":{"_uuid":"144588cf-9459-4d9e-bf05-7081c4f21b96","_cell_guid":"f809db7c-92b3-4c3e-a52a-c9654e809bba","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T10:14:09.183782Z","iopub.execute_input":"2025-03-08T10:14:09.184086Z","iopub.status.idle":"2025-03-08T10:14:12.590955Z","shell.execute_reply.started":"2025-03-08T10:14:09.184029Z","shell.execute_reply":"2025-03-08T10:14:12.590110Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\n\n# Define early stopping and model checkpoint callbacks\nearly_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\nmodel_checkpoint = ModelCheckpoint(\"best_model.h5\", monitor=\"val_loss\", save_best_only=True, verbose=1)\n\n# Compile the model and train it\nopt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n\tmetrics=[\"accuracy\"])\n\nprint(\"\"\"[INFO] compiling model...\n[INFO] training head...\"\"\")\n\n# Train the model with the callbacks\nH = model.fit(\n\tAugmentedData.flow(trainX, trainY, batch_size=BS),\n\tsteps_per_epoch=len(trainX) // BS,\n\tvalidation_data=(testX, testY),\n\tvalidation_steps=len(testX) // BS,\n\tepochs=EPOCHS,\n\tcallbacks=[early_stopping, model_checkpoint]\n)","metadata":{"_uuid":"82290a24-bfae-4c83-97df-fe2ed9c7f39c","_cell_guid":"ff7c450e-1b1c-4c3c-a93f-335fec0d2e5c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T10:14:12.591881Z","iopub.execute_input":"2025-03-08T10:14:12.592210Z","iopub.status.idle":"2025-03-08T10:39:39.756194Z","shell.execute_reply.started":"2025-03-08T10:14:12.592175Z","shell.execute_reply":"2025-03-08T10:39:39.755422Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"[INFO] evaluating network...\")\npredIdxs = model.predict(testX, batch_size=BS)\n\n# for each image in the testing set we need to find the index of the\n# label with corresponding largest predicted probability\npredIdxs = np.argmax(predIdxs, axis=1)\n\n# show a nicely formatted classification report\nprint(classification_report(testY.argmax(axis=1), predIdxs\n\t))\n\n# # serialize the model to disk\n# print(\"[INFO] saving mask detector model...\")\n\n# plot the training loss and accuracy\n# Sửa lại đoạn mã vẽ\nN = len(H.history[\"loss\"])  # Lấy số epoch thực tế từ quá trình huấn luyện\nplt.style.use(\"ggplot\")\nplt.figure()\n\n# Vẽ đồ thị\nplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n\n# Thêm các phần tử đồ thị khác\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend()\nplt.show()\n","metadata":{"_uuid":"5b82ab45-a90d-467d-93bb-1b2d9a8ebbf9","_cell_guid":"fa5b4319-9d59-4f9a-bd66-dd9c634c65f1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T10:50:54.551721Z","iopub.execute_input":"2025-03-08T10:50:54.552144Z","iopub.status.idle":"2025-03-08T10:50:59.739921Z","shell.execute_reply.started":"2025-03-08T10:50:54.552113Z","shell.execute_reply":"2025-03-08T10:50:59.738924Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"my_mask_detector_1.h5\")","metadata":{"_uuid":"7483c3c3-9ccc-4192-bce5-ecdf2612599b","_cell_guid":"348a59fb-6697-4829-9649-284908702d9f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-08T10:39:45.204044Z","iopub.status.idle":"2025-03-08T10:39:45.204355Z","shell.execute_reply":"2025-03-08T10:39:45.204217Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}